{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZC2wVfZz8qi",
        "outputId": "bea3d120-ad3d-4a5b-d359-9f5cc89beb3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset create from coco json\n"
      ],
      "metadata": {
        "id": "JqEluDSKAStA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NLrZ2iL2x-Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------\n",
        "# CONFIG\n",
        "# -------------------\n",
        "\n",
        "\n",
        "ANNOTATIONS_JSON = r\"/content/drive/MyDrive/labels_test_catarct.json\"   # <- your COCO JSON from makesense.ai\n",
        "IMAGES_ROOT      = r\"/content/drive/MyDrive/processed_images/test/cataract\"        # <- folder containing images (can be nested)\n",
        "OUTPUT_DIR       = r\"/content/drive/MyDrive/processed_images_pupil/test/cataract\"                      # <- where to save cropped images\n",
        "\n",
        "PADDING          = 0.1                           # % padding around bbox\n",
        "\n",
        "\n",
        "def clamp(val, lo, hi):\n",
        "    return max(lo, min(val, hi))\n",
        "\n",
        "\n",
        "def main():\n",
        "    with open(ANNOTATIONS_JSON, \"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    images_by_id = {img[\"id\"]: img for img in coco[\"images\"]}\n",
        "    out_root = Path(OUTPUT_DIR)\n",
        "    out_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    saved, skipped = 0, 0\n",
        "\n",
        "    for ann in tqdm(coco[\"annotations\"], desc=\"Cropping circular\"):\n",
        "        img_id = ann[\"image_id\"]\n",
        "        img_info = images_by_id.get(img_id)\n",
        "        if not img_info:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        img_path = Path(IMAGES_ROOT) / img_info[\"file_name\"]\n",
        "        if not img_path.exists():\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            skipped += 1\n",
        "            continue\n",
        "        H, W = img.shape[:2]\n",
        "\n",
        "        if \"bbox\" not in ann:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        x, y, w, h = ann[\"bbox\"]\n",
        "\n",
        "        # Add padding\n",
        "        px, py = PADDING * w, PADDING * h\n",
        "        x1 = clamp(int(x - px), 0, W)\n",
        "        y1 = clamp(int(y - py), 0, H)\n",
        "        x2 = clamp(int(x + w + px), 0, W)\n",
        "        y2 = clamp(int(y + h + py), 0, H)\n",
        "\n",
        "        # Crop region\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        if crop.size == 0:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        # Create circular mask\n",
        "        h_crop, w_crop = crop.shape[:2]\n",
        "        cx, cy = w_crop // 2, h_crop // 2\n",
        "        radius = min(cx, cy)\n",
        "        mask = np.zeros((h_crop, w_crop), dtype=np.uint8)\n",
        "        cv2.circle(mask, (cx, cy), radius, 255, -1)\n",
        "\n",
        "        # Apply mask with black background\n",
        "        result = np.zeros_like(crop)  # black background\n",
        "        for c in range(3):\n",
        "            result[:,:,c] = cv2.bitwise_and(crop[:,:,c], crop[:,:,c], mask=mask)\n",
        "\n",
        "        # Save as JPG (3-channel, no alpha)\n",
        "        base = Path(img_info[\"file_name\"]).stem\n",
        "        out_name = f\"{base}_img{img_id}_ann{ann['id']}.jpg\"\n",
        "        out_path = out_root / out_name\n",
        "        cv2.imwrite(str(out_path), result)\n",
        "        saved += 1\n",
        "\n",
        "    print(f\"\\n✅ Done. Saved: {saved} circular crops, Skipped: {skipped}.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kslmAij91Neo",
        "outputId": "aa6f2623-3521-4525-c4c0-63fc596d3d1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cropping circular: 100%|██████████| 61/61 [00:03<00:00, 15.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Done. Saved: 61 circular crops, Skipped: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}