{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNdTkmD2Asb5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAydIgIBBo_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SQ0ZMLFDkpo"
      },
      "source": [
        "Merge All images from different folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqkP9WmdDoAo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Paths\n",
        "source_root = \"/content/drive/MyDrive/cataract/Normal/\"   # parent folder that contains many subfolders with images\n",
        "destination = \"/content/drive/MyDrive/processed_images/train/normal/\"\n",
        "\n",
        "# Create destination folder if not exists\n",
        "os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "# Allowed image extensions\n",
        "extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
        "\n",
        "# Counter for unique filenames\n",
        "counter = 1\n",
        "\n",
        "for root, dirs, files in os.walk(source_root):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(extensions):\n",
        "            src_path = os.path.join(root, file)\n",
        "\n",
        "            # Create unique filename to avoid overwriting\n",
        "            new_filename = f\"image_{counter}{os.path.splitext(file)[1]}\"\n",
        "            dst_path = os.path.join(destination, new_filename)\n",
        "\n",
        "            shutil.copy2(src_path, dst_path)  # copy image\n",
        "            # shutil.move(src_path, dst_path)  # use this if you want to MOVE instead of copy\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "print(f\"‚úÖ All images have been merged into: {destination}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the main directory containing class folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/processed_images/train\"\n",
        "\n",
        "# Allowed image extensions\n",
        "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
        "\n",
        "# Loop through each subfolder\n",
        "for folder_name in os.listdir(DATA_DIR):\n",
        "    folder_path = os.path.join(DATA_DIR, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        count = len([\n",
        "            f for f in os.listdir(folder_path)\n",
        "            if f.lower().endswith(IMG_EXTENSIONS)\n",
        "        ])\n",
        "        print(f\"Folder '{folder_name}': {count} images\")\n"
      ],
      "metadata": {
        "id": "Lz5LSRuYat03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDIiJ8RdKxhz"
      },
      "source": [
        "create label.txt for yolo training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWFFpaZWK04i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "# ---- Config ----\n",
        "coco_json = \"/content/drive/MyDrive/labels_test_catarct.json\"   # COCO annotation file\n",
        "output_dir = \"/content/drive/MyDrive/only_pupil/labels\"          # where YOLO txt files will go\n",
        "images_dir = \"/content/drive/MyDrive/only_pupil/images\"          # your images folder\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ---- Load COCO ----\n",
        "with open(coco_json) as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "# Map image_id ‚Üí file_name\n",
        "id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in coco[\"images\"]}\n",
        "\n",
        "# Create YOLO txt per image\n",
        "for ann in tqdm(coco[\"annotations\"], desc=\"Converting\"):\n",
        "    img_id = ann[\"image_id\"]\n",
        "    bbox = ann[\"bbox\"]  # [x, y, width, height]\n",
        "\n",
        "    # Force single class (pupil = 0)\n",
        "    class_id = 0\n",
        "\n",
        "    # Convert to YOLO format\n",
        "    x, y, w, h = bbox\n",
        "    img_filename = id_to_filename[img_id]\n",
        "    img_path = os.path.join(images_dir, img_filename)\n",
        "\n",
        "    # Load image size (for normalization)\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"‚ö†Ô∏è Warning: Could not read image {img_path}. Skipping annotation.\")\n",
        "        continue\n",
        "\n",
        "    H, W = img.shape[:2]\n",
        "\n",
        "    x_center = (x + w / 2) / W\n",
        "    y_center = (y + h / 2) / H\n",
        "    w /= W\n",
        "    h /= H\n",
        "\n",
        "    # YOLO line\n",
        "    yolo_line = f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\"\n",
        "\n",
        "    # Save\n",
        "    label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "    with open(os.path.join(output_dir, label_filename), \"a\") as f:\n",
        "        f.write(yolo_line)\n",
        "\n",
        "print(\"‚úÖ COCO ‚Üí YOLO conversion complete! Labels saved in:\", output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ELbV2qNO8N"
      },
      "source": [
        "Split Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipILeMsjIGZD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX_zyNPyEUwe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# ---- Config ----\n",
        "images_dir = \"/content/drive/MyDrive/only_pupil/images\"   # all images\n",
        "labels_dir = \"/content/drive/MyDrive/only_pupil/labels\"   # all labels\n",
        "output_dir = \"/content/drive/MyDrive/only_pupil_split\"    # output root folder\n",
        "\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Create output folders\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(os.path.join(output_dir, \"images\", split), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"labels\", split), exist_ok=True)\n",
        "\n",
        "# Get all images\n",
        "all_images = [f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Split counts\n",
        "total = len(all_images)\n",
        "train_count = int(total * train_ratio)\n",
        "val_count = int(total * val_ratio)\n",
        "\n",
        "train_files = all_images[:train_count]\n",
        "val_files = all_images[train_count:train_count + val_count]\n",
        "test_files = all_images[train_count + val_count:]\n",
        "\n",
        "splits = {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
        "\n",
        "# Copy images and labels\n",
        "for split, files in splits.items():\n",
        "    for f in files:\n",
        "        # Copy image\n",
        "        shutil.copy2(os.path.join(images_dir, f), os.path.join(output_dir, \"images\", split, f))\n",
        "\n",
        "        # Copy corresponding label\n",
        "        label_file = os.path.splitext(f)[0] + \".txt\"\n",
        "        shutil.copy2(os.path.join(labels_dir, label_file), os.path.join(output_dir, \"labels\", split, label_file))\n",
        "\n",
        "print(\"‚úÖ Dataset split complete!\")\n",
        "print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYQivuz2V-Wk"
      },
      "source": [
        "Pupil Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trs8uACFWAvs"
      },
      "outputs": [],
      "source": [
        "pip install -U ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEAUiQtCWcmG",
        "outputId": "3a3f5cbb-a6a5-495a-835c-e07ee167017e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/cataract/pupil_detection/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.05, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_pupil_tuned2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_pupil, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs_pupil/yolov8_pupil_tuned2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.4¬±0.1 ms, read: 110.9¬±57.4 MB/s, size: 12540.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/cataract/pupil_detection/labels/train.cache... 244 images, 254 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 498/498 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.9¬±1.1 ms, read: 105.3¬±135.1 MB/s, size: 7759.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/cataract/pupil_detection/labels/val.cache... 127 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs_pupil/yolov8_pupil_tuned2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns_pupil/yolov8_pupil_tuned2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      1.69G      1.174      3.257      1.252          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:48<00:00,  5.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127    0.00733      0.291     0.0187    0.00397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      1.69G      1.062      1.576      1.174          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:44<00:00,  5.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.273      0.992      0.682      0.381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      1.69G      1.007      1.438      1.132          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:37<00:00,  4.93s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127       0.92      0.636       0.89      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      1.69G     0.9347       1.36      1.094          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:40<00:00,  5.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.918      0.819      0.937      0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      1.69G     0.9611       1.33      1.104          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:42<00:00,  5.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.945      0.941      0.984      0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      1.69G      0.932      1.274      1.047          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:43<00:00,  5.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.992      0.982      0.993       0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      1.69G     0.8748      1.227       1.07          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:42<00:00,  5.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.996      0.992      0.995      0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      1.69G     0.8623       1.23      1.014          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:40<00:00,  5.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127       0.99          1      0.995      0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      1.69G     0.8152      1.134     0.9981          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:42<00:00,  5.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.984      0.994      0.995      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      1.69G     0.7873       1.15     0.9762          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:46<00:00,  5.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127          1      0.998      0.995      0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.464 hours.\n",
            "Optimizer stripped from runs_pupil/yolov8_pupil_tuned2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs_pupil/yolov8_pupil_tuned2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs_pupil/yolov8_pupil_tuned2/weights/best.pt...\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:53<00:00, 13.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.993      0.992      0.995      0.789\n",
            "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns_pupil/yolov8_pupil_tuned2\u001b[0m\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/cataract/pupil_detection/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.05, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov10_pupil_tuned, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_pupil, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs_pupil/yolov10_pupil_tuned, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.2 ms, read: 93.8¬±55.5 MB/s, size: 12540.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/cataract/pupil_detection/labels/train.cache... 244 images, 254 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 498/498 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 7.8¬±14.1 ms, read: 37.9¬±38.4 MB/s, size: 7759.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/cataract/pupil_detection/labels/val.cache... 127 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127/127 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs_pupil/yolov10_pupil_tuned/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns_pupil/yolov10_pupil_tuned\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      1.68G      1.183       3.27      1.342          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [03:40<00:00,  6.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:17<00:00,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127    0.00362      0.236     0.0265    0.00612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      1.95G      1.017      1.569      1.225          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:32<00:00,  4.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.884       0.18      0.254      0.178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      1.95G     0.9847      1.406      1.164          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:45<00:00,  5.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.148     0.0709     0.0863     0.0483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      1.96G     0.9497      1.336      1.161          0        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:48<00:00,  5.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127       0.64      0.617      0.724      0.551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      1.96G     0.9569        1.3      1.168          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:52<00:00,  5.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.886      0.953      0.945      0.717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      1.96G     0.8939      1.232      1.099          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:51<00:00,  5.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.948      0.953      0.986      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      1.97G     0.8783      1.201      1.145          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:53<00:00,  5.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.992       0.99      0.995      0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      1.98G     0.8641       1.21      1.111          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:48<00:00,  5.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127          1      0.997      0.995      0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10         2G     0.8441      1.159      1.102          2        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:49<00:00,  5.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127      0.992      0.988      0.995      0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      2.01G     0.7965       1.17      1.059          1        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [02:57<00:00,  5.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127          1      0.991      0.995      0.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.499 hours.\n",
            "Optimizer stripped from runs_pupil/yolov10_pupil_tuned/weights/last.pt, 5.4MB\n",
            "Optimizer stripped from runs_pupil/yolov10_pupil_tuned/weights/best.pt, 5.4MB\n",
            "\n",
            "Validating runs_pupil/yolov10_pupil_tuned/weights/best.pt...\n",
            "Ultralytics 8.3.182 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:46<00:00, 11.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        127        127          1      0.991      0.995      0.793\n",
            "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns_pupil/yolov10_pupil_tuned\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# YOLOv8 model\n",
        "v8_model = YOLO(\"yolov8n.pt\")\n",
        "v8_results = v8_model.train(\n",
        "    data=\"/content/drive/MyDrive/cataract/pupil_detection/data.yaml\",\n",
        "    epochs=10,              # üëâ barate hobe (50 ‚Üí 100/150) for better convergence\n",
        "    imgsz=512,               # thik ache, but try 512 if GPU low\n",
        "    batch=16,\n",
        "    patience=30,             # üëâ early stopping\n",
        "    optimizer=\"AdamW\",       # üëâ better optimizer than SGD for small datasets\n",
        "    lr0=0.001,               # üëâ custom learning rate (default 0.01 too high)\n",
        "    lrf=0.01,                # final lr ratio\n",
        "    dropout=0.05,            # üëâ prevent overfitting\n",
        "    mosaic=1.0,              # üëâ enable strong augmentation\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, # üëâ color augmentation\n",
        "    scale=0.5, flipud=0.5, fliplr=0.5, # üëâ geometric augmentation\n",
        "    project=\"runs_pupil\",\n",
        "    name=\"yolov8_pupil_tuned\"\n",
        ")\n",
        "\n",
        "# YOLO latest (YOLOv10/11)\n",
        "v10_model = YOLO(\"yolo11n.pt\")\n",
        "v10_results = v10_model.train(\n",
        "    data=\"/content/drive/MyDrive/cataract/pupil_detection/data.yaml\",\n",
        "    epochs=10,\n",
        "    imgsz=512,\n",
        "    batch=16,\n",
        "    patience=30,\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    dropout=0.05,\n",
        "    mosaic=1.0,\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    scale=0.5, flipud=0.5, fliplr=0.5,\n",
        "    project=\"runs_pupil\",\n",
        "    name=\"yolov10_pupil_tuned\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b5tTR_Aiaqhi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "56337dad-2dcc-43f7-de1d-cece1eee03ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract metrics\n",
        "v8_metrics = v8_results.results_dict  # precision, recall, mAP50, mAP50-95\n",
        "v10_metrics = v10_results.results_dict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics to compare\n",
        "metrics_names = [\"Precision\", \"Recall\", \"mAP50\", \"mAP50-95\"]\n",
        "v8_values = [v8_metrics['metrics/precision(B)'], v8_metrics['metrics/recall(B)'], v8_metrics['metrics/mAP50(B)'], v8_metrics['metrics/mAP50-95(B)']]\n",
        "v10_values = [v10_metrics['metrics/precision(B)'], v10_metrics['metrics/recall(B)'], v10_metrics['metrics/mAP50(B)'], v10_metrics['metrics/mAP50-95(B)']]\n",
        "\n",
        "x = np.arange(len(metrics_names))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "rects1 = ax.bar(x - width/2, v8_values, width, label='YOLOv8', color='skyblue')\n",
        "rects2 = ax.bar(x + width/2, v10_values, width, label='YOLO Latest', color='salmon')\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Pupil Detection Performance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_names)\n",
        "ax.set_ylim(0,1)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                    xytext=(0,3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# Paths\n",
        "# -----------------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/processed_images/train/\"         # original dataset\n",
        "SAVE_DIR = \"/content/drive/MyDrive/processed_images_clean\"  # processed dataset\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Image processing settings\n",
        "# -----------------------------\n",
        "# FastNlMeansDenoisingColored parameters\n",
        "h = 10          # filter strength for luminance\n",
        "hColor = 10     # filter strength for color\n",
        "templateWindowSize = 7\n",
        "searchWindowSize = 21\n",
        "\n",
        "# Sharpening kernel\n",
        "sharpen_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "sharpen_filter = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]], dtype=np.float32)\n",
        "\n",
        "# -----------------------------\n",
        "# Process images\n",
        "# -----------------------------\n",
        "for class_name in os.listdir(DATA_DIR):\n",
        "    class_path = os.path.join(DATA_DIR, class_name)\n",
        "    save_class_path = os.path.join(SAVE_DIR, class_name)\n",
        "    os.makedirs(save_class_path, exist_ok=True)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        for img_name in tqdm(os.listdir(class_path), desc=f\"Processing {class_name}\"):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # 1Ô∏è‚É£ Noise removal\n",
        "            denoised = cv2.fastNlMeansDenoisingColored(img, None, h, hColor,\n",
        "                                                       templateWindowSize, searchWindowSize)\n",
        "\n",
        "            # 2Ô∏è‚É£ Mild sharpening\n",
        "            sharpened = cv2.filter2D(denoised, -1, sharpen_filter)\n",
        "\n",
        "            # Save processed image\n",
        "            save_path = os.path.join(save_class_path, img_name)\n",
        "            cv2.imwrite(save_path, sharpened)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER6nCFWdMboU",
        "outputId": "609bfbd0-cd8f-4f12-8054-bc988954bc55"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing cataract: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 876/876 [14:20<00:00,  1.02it/s]\n",
            "Processing normal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 804/804 [11:30<00:00,  1.16it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}